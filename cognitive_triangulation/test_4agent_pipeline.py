#!/usr/bin/env python3
"""
Full 4-Agent Pipeline Test - CodeScout ‚Üí RelationshipDetector ‚Üí ContextAnalyzer ‚Üí ConfidenceAggregator
Tests the complete evidence-gathering pipeline before LLM approval
"""

import sys
import os
import time

# Add paths for imports
sys.path.append('/Users/bobdallavia/X-Agent-Pipeline-CognitiveTriangulation/agent_performance_test')
sys.path.append('/Users/bobdallavia/X-Agent-Pipeline-CognitiveTriangulation/cognitive_triangulation/agents')

from colocated_plugin_agent import CoLocatedPluginCodeScoutAgent
from relationship_detector_agent import RelationshipDetectorAgent
from context_analyzer_agent import ContextAnalyzerAgent
from confidence_aggregator_agent import ConfidenceAggregatorAgent

def test_full_4_agent_pipeline():
    print("üöÄ COGNITIVE TRIANGULATION 4-AGENT EVIDENCE PIPELINE")
    print("=" * 80)
    
    # Load sample code
    sample_file_path = '/Users/bobdallavia/X-Agent-Pipeline-CognitiveTriangulation/agent_performance_test/sample_code.py'
    with open(sample_file_path, 'r') as f:
        test_content = f.read()
    
    print(f"üìÅ Test file loaded: {len(test_content)} characters")
    
    # Step 1: CodeScout Agent
    print("\nüîç STEP 1: Code Scout Agent (POI Detection)")
    print("-" * 60)
    
    scout_input = f"""<?xml version="1.0" encoding="UTF-8"?>
<CodeAnalysisInput>
    <FilePath>{sample_file_path}</FilePath>
    <Content><![CDATA[{test_content}]]></Content>
</CodeAnalysisInput>"""
    
    scout_agent = CoLocatedPluginCodeScoutAgent()
    start_time = time.perf_counter()
    scout_output = scout_agent.process(scout_input)
    scout_time = (time.perf_counter() - start_time) * 1000
    
    print(f"‚úÖ CodeScout completed in {scout_time:.2f}ms")
    print(f"üìÑ Output length: {len(scout_output)} characters")
    scout_pois = scout_output.count('<POI')
    print(f"üéØ POIs detected: {scout_pois}")
    
    # Step 2: RelationshipDetector Agent
    print("\nüîó STEP 2: Relationship Detector Agent")
    print("-" * 60)
    
    relationship_agent = RelationshipDetectorAgent()
    start_time = time.perf_counter()
    relationship_output = relationship_agent.process(scout_output)
    relationship_time = (time.perf_counter() - start_time) * 1000
    
    print(f"‚úÖ RelationshipDetector completed in {relationship_time:.2f}ms")
    print(f"üìÑ Output length: {len(relationship_output)} characters")
    relationships_found = relationship_output.count('<Relationship')
    print(f"üîó Relationships detected: {relationships_found}")
    
    # Step 3: ContextAnalyzer Agent
    print("\nüß† STEP 3: Context Analyzer Agent (Semantic Analysis)")
    print("-" * 60)
    
    context_agent = ContextAnalyzerAgent()
    start_time = time.perf_counter()
    context_output = context_agent.process(relationship_output)
    context_time = (time.perf_counter() - start_time) * 1000
    
    print(f"‚úÖ ContextAnalyzer completed in {context_time:.2f}ms")
    print(f"üìÑ Output length: {len(context_output)} characters")
    patterns_found = context_output.count('<Pattern')
    print(f"üß† Semantic patterns detected: {patterns_found}")
    
    # Step 4: ConfidenceAggregator Agent
    print("\nüìä STEP 4: Confidence Aggregator Agent (Mathematical Scoring)")
    print("-" * 60)
    
    confidence_agent = ConfidenceAggregatorAgent()
    start_time = time.perf_counter()
    confidence_output = confidence_agent.process(context_output)
    confidence_time = (time.perf_counter() - start_time) * 1000
    
    print(f"‚úÖ ConfidenceAggregator completed in {confidence_time:.2f}ms")
    print(f"üìÑ Output length: {len(confidence_output)} characters")
    
    # Extract confidence metrics
    import re
    overall_confidence_match = re.search(r'name="overall_confidence" value="([^"]+)"', confidence_output)
    overall_confidence = float(overall_confidence_match.group(1)) if overall_confidence_match else 0.0
    
    analysis_quality_match = re.search(r'name="analysis_quality" value="([^"]+)"', confidence_output)
    analysis_quality = float(analysis_quality_match.group(1)) if analysis_quality_match else 0.0
    
    ready_for_approval = 'true' in re.search(r'<ReadyForApproval>([^<]+)', confidence_output).group(1) if re.search(r'<ReadyForApproval>([^<]+)', confidence_output) else False
    
    high_confidence_rels = confidence_output.count('<HighConfidenceRelationships>') and confidence_output.count('</HighConfidenceRelationships>') 
    high_confidence_patterns = confidence_output.count('<HighConfidencePatterns>') and confidence_output.count('</HighConfidencePatterns>')
    
    # Pipeline Summary
    total_time = scout_time + relationship_time + context_time + confidence_time
    print(f"\nüìä COMPLETE 4-AGENT EVIDENCE PIPELINE SUMMARY")
    print("=" * 80)
    print(f"üéØ Total POIs: {scout_pois}")
    print(f"üîó Total Relationships: {relationships_found}")
    print(f"üß† Total Semantic Patterns: {patterns_found}")
    print(f"üìä Overall Confidence: {overall_confidence:.1%}")
    print(f"üìà Analysis Quality: {analysis_quality:.1%}")
    print(f"‚úÖ Ready for LLM Approval: {ready_for_approval}")
    print(f"")
    print(f"‚è±Ô∏è  CodeScout Time: {scout_time:.2f}ms")
    print(f"‚è±Ô∏è  RelationshipDetector Time: {relationship_time:.2f}ms")
    print(f"‚è±Ô∏è  ContextAnalyzer Time: {context_time:.2f}ms")
    print(f"‚è±Ô∏è  ConfidenceAggregator Time: {confidence_time:.2f}ms")
    print(f"‚ö° Total Evidence Pipeline Time: {total_time:.2f}ms")
    
    total_items = scout_pois + relationships_found + patterns_found
    print(f"üìà Total Analysis Items: {total_items}")
    print(f"üìà Pipeline Efficiency: {total_time/max(1, total_items):.3f}ms per item")
    
    # Performance Analysis
    print(f"\nüöÄ EVIDENCE PIPELINE PERFORMANCE:")
    print("-" * 60)
    print(f"‚Ä¢ Ultra-fast POI detection: {scout_time < 1.0} ({scout_time:.2f}ms)")
    print(f"‚Ä¢ Fast relationship detection: {relationship_time < 5.0} ({relationship_time:.2f}ms)")
    print(f"‚Ä¢ Fast semantic analysis: {context_time < 5.0} ({context_time:.2f}ms)")
    print(f"‚Ä¢ Ultra-fast confidence scoring: {confidence_time < 1.0} ({confidence_time:.2f}ms)")
    print(f"‚Ä¢ Sub-10ms total evidence pipeline: {total_time < 10.0} ({total_time:.2f}ms)")
    
    # Quality Analysis
    print(f"\nüìä EVIDENCE QUALITY ANALYSIS:")
    print("-" * 60)
    print(f"‚Ä¢ POI detection coverage: {scout_pois} items")
    print(f"‚Ä¢ Relationship coverage: {relationships_found}/{scout_pois} = {relationships_found/max(1,scout_pois)*100:.1f}%")
    print(f"‚Ä¢ Pattern detection density: {patterns_found} semantic patterns")
    print(f"‚Ä¢ Mathematical confidence score: {overall_confidence:.1%}")
    print(f"‚Ä¢ Analysis quality score: {analysis_quality:.1%}")
    print(f"‚Ä¢ Evidence pipeline completeness: ‚úÖ")
    
    # Show confidence aggregation sample
    print(f"\nüìã CONFIDENCE AGGREGATOR OUTPUT SAMPLE:")
    print("-" * 60)
    lines = confidence_output.split('\n')
    for i, line in enumerate(lines[:30]):
        print(f"{i+1:2d}: {line}")
    if len(lines) > 30:
        print("    ... (output truncated)")
    
    # Save outputs for inspection
    with open('pipeline_4agent_scout.xml', 'w') as f:
        f.write(scout_output)
    
    with open('pipeline_4agent_relationships.xml', 'w') as f:
        f.write(relationship_output)
        
    with open('pipeline_4agent_context.xml', 'w') as f:
        f.write(context_output)
        
    with open('pipeline_4agent_confidence.xml', 'w') as f:
        f.write(confidence_output)
    
    print(f"\nüíæ All evidence pipeline outputs saved:")
    print(f"   pipeline_4agent_scout.xml")
    print(f"   pipeline_4agent_relationships.xml")
    print(f"   pipeline_4agent_context.xml")
    print(f"   pipeline_4agent_confidence.xml")
    
    # Ultimate comparison
    print(f"\nüéØ ULTIMATE COMPARISON: X-AGENTS vs ORIGINAL COGNITIVE TRIANGULATION")
    print("=" * 80)
    original_time_estimate = 30000  # 30+ seconds
    speedup = original_time_estimate / total_time
    
    print(f"üìä Original Cognitive Triangulation:")
    print(f"   ‚Ä¢ Time: ~{original_time_estimate/1000:.0f}+ seconds")
    print(f"   ‚Ä¢ Cost: Hundreds of LLM API calls")
    print(f"   ‚Ä¢ Method: Multiple LLM passes for triangulation")
    print(f"   ‚Ä¢ Reliability: High but inconsistent")
    print(f"")
    print(f"üìä Our X-Agent Evidence Pipeline:")
    print(f"   ‚Ä¢ Time: {total_time:.2f}ms")
    print(f"   ‚Ä¢ Cost: $0 (no LLM calls for evidence gathering)")
    print(f"   ‚Ä¢ Method: 4 specialized X-Agents + mathematical scoring")
    print(f"   ‚Ä¢ Reliability: {analysis_quality:.1%} deterministic quality")
    print(f"")
    print(f"üöÄ **INCREDIBLE ACHIEVEMENTS:**")
    print(f"   ‚Ä¢ Speed Improvement: **{speedup:,.0f}x faster!**")
    print(f"   ‚Ä¢ Cost Reduction: **100%** (zero LLM tokens for evidence)")
    print(f"   ‚Ä¢ Analysis Depth: **{total_items} items** analyzed comprehensively")
    print(f"   ‚Ä¢ Mathematical Confidence: **{overall_confidence:.1%}** evidence-based scoring")
    print(f"   ‚Ä¢ Ready for Final LLM Approval: **{ready_for_approval}**")
    
    return {
        'scout_time_ms': scout_time,
        'relationship_time_ms': relationship_time,
        'context_time_ms': context_time,
        'confidence_time_ms': confidence_time,
        'total_time_ms': total_time,
        'pois_found': scout_pois,
        'relationships_found': relationships_found,
        'patterns_found': patterns_found,
        'overall_confidence': overall_confidence,
        'analysis_quality': analysis_quality,
        'ready_for_approval': ready_for_approval,
        'speedup_factor': speedup
    }

if __name__ == "__main__":
    results = test_full_4_agent_pipeline()
    
    print(f"\nüéâ 4-AGENT EVIDENCE PIPELINE COMPLETE!")
    print(f"   Mathematical confidence scoring: {results['overall_confidence']:.1%}")
    print(f"   Evidence pipeline performing at {results['speedup_factor']:,.0f}x original speed!")
    print(f"   Ready to build final LLMApprover agent for executive decision!")
