#!/usr/bin/env python3
"""
Enhanced Cognitive Triangulation Analysis of Original X-Agent Concepts
Testing our enhanced system on the XML-MCP Template - the foundational X-Agent architecture

This demonstrates meta-analysis: using our enhanced cognitive triangulation system
to analyze the original X-Agent concepts and architecture.
"""
import sys
import os
import time
import asyncio
from pathlib import Path

# Add our enhanced system path
sys.path.append('/Users/bobdallavia/X-Agent-Pipeline-CognitiveTriangulation')

# Import our enhanced agents (checking which ones exist)
try:
    from agents.specialized.code_scout_agent import CodeScoutAgent
    from agents.specialized.relationship_detector_agent import RelationshipDetectorAgent  
    from agents.specialized.context_analyzer_agent import ContextAnalyzerAgent
    from agents.specialized.confidence_aggregator_agent import ConfidenceAggregatorAgent
    DETERMINISTIC_AGENTS_AVAILABLE = True
    print("‚úÖ Deterministic agents loaded successfully")
except ImportError as e:
    print(f"‚ö†Ô∏è Some deterministic agents not found: {e}")
    DETERMINISTIC_AGENTS_AVAILABLE = False

try:
    from agents.specialized.semantic_analysis_agent import SemanticAnalysisAgent
    from agents.specialized.architectural_insight_agent import ArchitecturalInsightAgent
    STRATEGIC_AGENTS_AVAILABLE = True
    print("‚úÖ Strategic LLM agents loaded successfully")
except ImportError as e:
    print(f"‚ö†Ô∏è Strategic agents not found: {e}")
    STRATEGIC_AGENTS_AVAILABLE = False

async def analyze_original_x_agent_concepts():
    """
    Analyze the original X-Agent XML-MCP Template using our enhanced cognitive triangulation
    """
    
    print("üß† ENHANCED COGNITIVE TRIANGULATION: ANALYZING ORIGINAL X-AGENT CONCEPTS")
    print("=" * 80)
    print("üéØ Target: XML-MCP Template (Foundational X-Agent Architecture)")
    print("üî¨ Method: 6-Agent Enhanced Cognitive Triangulation")
    print("üí° Goal: Meta-analysis of original X-Agent design patterns")
    print()
    
    # Load the XML processor code
    xml_processor_path = '/Users/bobdallavia/XML-MCP-TEMPLATE/app/processors/xml_processor.py'
    
    try:
        with open(xml_processor_path, 'r') as f:
            xml_processor_code = f.read()
    except FileNotFoundError:
        print(f"‚ùå Could not find XML processor at: {xml_processor_path}")
        return
    
    print(f"üìÅ Analyzing: xml_processor.py ({len(xml_processor_code)} characters)")
    print(f"üìä Lines of code: {len(xml_processor_code.splitlines())}")
    print()
    
    pipeline_times = []
    total_start = time.time()
    
    # =====================================
    # Phase 1: Deterministic Core Analysis
    # =====================================
    
    if DETERMINISTIC_AGENTS_AVAILABLE:
        print("üöÄ PHASE 1: DETERMINISTIC CORE ANALYSIS (Ultra-Fast)")
        print("=" * 60)
        
        # Step 1: CodeScoutAgent - POI Detection
        print("üîç STEP 1: CodeScoutAgent (POI Detection)")
        print("-" * 40)
        
        code_scout = CodeScoutAgent()
        scout_input = f'''<code_analysis_request>
            <file_path>xml_processor.py</file_path>
            <file_content>{xml_processor_code}</file_content>
            <language>python</language>
            <analysis_depth>comprehensive</analysis_depth>
        </code_analysis_request>'''
        
        start_time = time.time()
        scout_result = code_scout.process(scout_input)
        scout_time = time.time() - start_time
        pipeline_times.append(('CodeScout', scout_time))
        
        # Parse results
        import xml.etree.ElementTree as ET
        scout_root = ET.fromstring(scout_result)
        pois_detected = len(scout_root.findall('.//poi'))
        
        print(f"‚ö° Processing Time: {scout_time * 1000:.3f}ms")
        print(f"üéØ POIs Detected: {pois_detected}")
        
        # Show some detected POIs
        print(f"üìã Sample POIs:")
        for i, poi in enumerate(scout_root.findall('.//poi')[:5], 1):
            poi_type = poi.find('type').text if poi.find('type') is not None else 'unknown'
            poi_name = poi.find('name').text if poi.find('name') is not None else 'unnamed'
            print(f"   {i}. {poi_type}: {poi_name}")
        
        # Step 2: RelationshipDetectorAgent
        print(f"\nüîó STEP 2: RelationshipDetectorAgent (Relationship Analysis)")
        print("-" * 40)
        
        relationship_detector = RelationshipDetectorAgent()
        start_time = time.time()
        relationship_result = relationship_detector.process(scout_result)
        rel_time = time.time() - start_time
        pipeline_times.append(('RelationshipDetector', rel_time))
        
        rel_root = ET.fromstring(relationship_result)
        relationships_detected = len(rel_root.findall('.//relationship'))
        avg_confidence = float(rel_root.find('.//avg_confidence').text)
        
        print(f"‚ö° Processing Time: {rel_time * 1000:.3f}ms")
        print(f"üîó Relationships Detected: {relationships_detected}")
        print(f"üìä Average Confidence: {avg_confidence:.1f}%")
        
        # Show sample relationships
        print(f"üîó Sample Relationships:")
        for i, rel in enumerate(rel_root.findall('.//relationship')[:3], 1):
            source = rel.find('source').text if rel.find('source') is not None else 'unknown'
            target = rel.find('target').text if rel.find('target') is not None else 'unknown'
            rel_type = rel.find('type').text if rel.find('type') is not None else 'unknown'
            print(f"   {i}. {source} --{rel_type}--> {target}")
        
        # Step 3: ContextAnalyzerAgent
        print(f"\nüß† STEP 3: ContextAnalyzerAgent (Pattern Recognition)")
        print("-" * 40)
        
        context_analyzer = ContextAnalyzerAgent()
        start_time = time.time()
        context_result = context_analyzer.process(relationship_result)
        context_time = time.time() - start_time
        pipeline_times.append(('ContextAnalyzer', context_time))
        
        context_root = ET.fromstring(context_result)
        patterns_detected = int(context_root.find('.//patterns_detected').text)
        semantic_comprehension = float(context_root.find('.//semantic_comprehension').text)
        
        print(f"‚ö° Processing Time: {context_time * 1000:.3f}ms")
        print(f"üß† Patterns Detected: {patterns_detected}")
        print(f"üìà Semantic Comprehension: {semantic_comprehension:.1f}%")
        
        # Show detected patterns
        print(f"üé® Detected Patterns:")
        for i, pattern in enumerate(context_root.findall('.//pattern')[:3], 1):
            pattern_name = pattern.find('name').text if pattern.find('name') is not None else 'unknown'
            pattern_type = pattern.find('type').text if pattern.find('type') is not None else 'unknown'
            print(f"   {i}. {pattern_name} ({pattern_type})")
        
        # Step 4: ConfidenceAggregatorAgent
        print(f"\nüìä STEP 4: ConfidenceAggregatorAgent (Evidence Aggregation)")
        print("-" * 40)
        
        # Create aggregated input
        aggregated_input = f'''<?xml version="1.0" encoding="UTF-8"?>
<pipeline_evidence>
  {scout_result.replace('<?xml version="1.0" encoding="UTF-8"?>', '')}
  {relationship_result.replace('<?xml version="1.0" encoding="UTF-8"?>', '')}
  {context_result.replace('<?xml version="1.0" encoding="UTF-8"?>', '')}
</pipeline_evidence>'''
        
        confidence_aggregator = ConfidenceAggregatorAgent()
        start_time = time.time()
        confidence_result = confidence_aggregator.process(aggregated_input)
        agg_time = time.time() - start_time
        pipeline_times.append(('ConfidenceAggregator', agg_time))
        
        confidence_root = ET.fromstring(confidence_result)
        overall_confidence = float(confidence_root.find('.//overall_confidence').text)
        evidence_quality = float(confidence_root.find('.//evidence_quality_ratio').text)
        high_confidence_items = int(confidence_root.find('.//high_confidence_items').text)
        
        print(f"‚ö° Processing Time: {agg_time * 1000:.3f}ms")
        print(f"üéØ Overall Confidence: {overall_confidence:.1f}%")
        print(f"üìä Evidence Quality: {evidence_quality:.1f}%")
        print(f"‚≠ê High-Confidence Items: {high_confidence_items}")
        
        deterministic_time = sum(time for _, time in pipeline_times) * 1000
        
    else:
        print("‚ö†Ô∏è Skipping deterministic analysis - agents not available")
        confidence_result = None
        overall_confidence = 75.0  # Simulate for strategic analysis
    
    # =====================================
    # Phase 2: Strategic LLM Enhancement
    # =====================================
    
    if STRATEGIC_AGENTS_AVAILABLE and confidence_result:
        print(f"\nüß† PHASE 2: STRATEGIC LLM ENHANCEMENT (Intelligent Analysis)")
        print("=" * 60)
        
        # Step 5: SemanticAnalysisAgent
        print("üéì STEP 5: SemanticAnalysisAgent (Edge Case & Semantic Analysis)")
        print("-" * 40)
        
        semantic_analyzer = SemanticAnalysisAgent()
        start_time = time.time()
        
        # Extract evidence for semantic analysis
        semantic_evidence = semantic_analyzer._extract_evidence_items(confidence_root)
        semantic_results = await semantic_analyzer._perform_semantic_analysis(
            semantic_evidence, overall_confidence
        )
        
        semantic_time = time.time() - start_time
        pipeline_times.append(('SemanticAnalysis', semantic_time))
        
        semantic_relationships = len(semantic_results.get('semantic_relationships', []))
        edge_cases = len(semantic_results.get('edge_cases_found', []))
        semantic_insights = len(semantic_results.get('semantic_insights', []))
        
        print(f"‚ö° Processing Time: {semantic_time * 1000:.3f}ms")
        print(f"üîó Semantic Relationships: {semantic_relationships}")
        print(f"üö® Edge Cases Found: {edge_cases}")
        print(f"üí° Semantic Insights: {semantic_insights}")
        print(f"üí∞ Estimated Cost: ${semantic_analyzer.metrics['cost_estimate_cents']:.4f}")
        
        # Show key insights
        print(f"üí° Key Semantic Insights:")
        for i, insight in enumerate(semantic_results.get('semantic_insights', [])[:3], 1):
            print(f"   {i}. {insight.get('insight', 'N/A')} ({insight.get('confidence', 0):.0f}% confidence)")
        
        # Step 6: ArchitecturalInsightAgent
        print(f"\nüèóÔ∏è STEP 6: ArchitecturalInsightAgent (High-Level Architecture Analysis)")
        print("-" * 40)
        
        # Prepare input for architectural analysis
        architectural_input = f'''<?xml version="1.0" encoding="UTF-8"?>
<comprehensive_analysis>
  {confidence_result.replace('<?xml version="1.0" encoding="UTF-8"?>', '')}
</comprehensive_analysis>'''
        
        architectural_agent = ArchitecturalInsightAgent()
        start_time = time.time()
        
        # Extract and analyze
        arch_root = ET.fromstring(architectural_input)
        analysis_data = architectural_agent._extract_analysis_data(arch_root)
        architectural_results = await architectural_agent._perform_architectural_analysis(analysis_data)
        
        arch_time = time.time() - start_time
        pipeline_times.append(('ArchitecturalInsight', arch_time))
        
        arch_assessment = architectural_results.get('architectural_assessment', {})
        tech_debt_items = len(architectural_results.get('technical_debt', []))
        improvement_recs = len(architectural_results.get('improvement_recommendations', []))
        strategic_recs = len(architectural_results.get('strategic_recommendations', []))
        
        print(f"‚ö° Processing Time: {arch_time * 1000:.3f}ms")
        print(f"üèÜ Overall Quality: {arch_assessment.get('overall_quality', 'unknown')}")
        print(f"üîß Maintainability Score: {arch_assessment.get('maintainability_score', 0):.1f}%")
        print(f"üìà Scalability Score: {arch_assessment.get('scalability_score', 0):.1f}%")
        print(f"‚ö†Ô∏è Technical Debt Items: {tech_debt_items}")
        print(f"‚úÖ Improvement Recommendations: {improvement_recs}")
        print(f"üéØ Strategic Recommendations: {strategic_recs}")
        print(f"üí∞ Estimated Cost: ${architectural_agent.metrics['cost_estimate_cents']:.4f}")
        
    else:
        print("‚ö†Ô∏è Skipping strategic analysis - agents not available or no confidence data")
        semantic_time = arch_time = 0
        semantic_results = architectural_results = {}
    
    # =====================================
    # Final Results & Analysis
    # =====================================
    
    total_time = time.time() - total_start
    
    print(f"\n" + "=" * 80)
    print("üéâ COGNITIVE TRIANGULATION OF ORIGINAL X-AGENT CONCEPTS COMPLETE!")
    print("=" * 80)
    
    if DETERMINISTIC_AGENTS_AVAILABLE:
        print(f"\n‚ö° PERFORMANCE SUMMARY:")
        print(f"{'Agent':<20} | {'Time (ms)':<10} | {'Type':<12} | {'Status'}")
        print("-" * 60)
        for agent_name, agent_time in pipeline_times:
            time_ms = agent_time * 1000
            agent_type = "LLM" if agent_name in ['SemanticAnalysis', 'ArchitecturalInsight'] else "Deterministic"
            status = "üöÄ FAST" if time_ms < 1.0 else "‚ö° GOOD" if time_ms < 10.0 else "üß† LLM"
            print(f"{agent_name:<20} | {time_ms:>7.3f}   | {agent_type:<12} | {status}")
        
        llm_time = (semantic_time + arch_time) * 1000 if STRATEGIC_AGENTS_AVAILABLE else 0
        total_time_ms = total_time * 1000
        
        print(f"\nüìä PIPELINE ANALYSIS:")
        print(f"Total Processing Time: {total_time_ms:.3f}ms")
        if DETERMINISTIC_AGENTS_AVAILABLE:
            print(f"Deterministic Core: {deterministic_time:.3f}ms ({(deterministic_time/total_time_ms)*100:.1f}%)")
        if STRATEGIC_AGENTS_AVAILABLE:
            print(f"Strategic LLM: {llm_time:.3f}ms ({(llm_time/total_time_ms)*100:.1f}%)")
            total_cost = semantic_analyzer.metrics['cost_estimate_cents'] + architectural_agent.metrics['cost_estimate_cents']
            print(f"Estimated Cost: ${total_cost:.4f}")
    
    # Analysis of Original X-Agent Concepts
    print(f"\nüéØ ANALYSIS OF ORIGINAL X-AGENT CONCEPTS:")
    print("=" * 50)
    
    if DETERMINISTIC_AGENTS_AVAILABLE:
        print(f"üìä Core Architecture Analysis:")
        print(f"   ‚Ä¢ POIs Detected: {pois_detected} (classes, methods, functions)")
        print(f"   ‚Ä¢ Relationships: {relationships_detected} (dependencies, inheritance)")
        print(f"   ‚Ä¢ Design Patterns: {patterns_detected} (architectural patterns)")
        print(f"   ‚Ä¢ Overall Confidence: {overall_confidence:.1f}%")
    
    if STRATEGIC_AGENTS_AVAILABLE and 'architectural_assessment' in architectural_results:
        arch_assessment = architectural_results['architectural_assessment']
        print(f"\nüèóÔ∏è Architectural Assessment of Original X-Agent:")
        print(f"   ‚Ä¢ Quality Level: {arch_assessment.get('overall_quality', 'unknown').title()}")
        print(f"   ‚Ä¢ Maintainability: {arch_assessment.get('maintainability_score', 0):.1f}%")
        print(f"   ‚Ä¢ Scalability: {arch_assessment.get('scalability_score', 0):.1f}%")
        print(f"   ‚Ä¢ Dominant Patterns: {', '.join(arch_assessment.get('dominant_patterns', []))}")
        
        print(f"\nüí° Key Insights about Original X-Agent Design:")
        for i, insight in enumerate(architectural_results.get('architectural_insights', [])[:3], 1):
            print(f"   {i}. {insight.get('insight', 'N/A')}")
        
        print(f"\nüîß Strategic Recommendations for X-Agent Evolution:")
        for i, rec in enumerate(architectural_results.get('strategic_recommendations', [])[:3], 1):
            print(f"   {i}. {rec.get('recommendation', 'N/A')}")
    
    print(f"\nüèÜ META-ANALYSIS CONCLUSIONS:")
    print("=" * 50)
    print("‚úÖ Our Enhanced Cognitive Triangulation successfully analyzed the original X-Agent concepts")
    print("‚úÖ Demonstrated hybrid approach: fast deterministic analysis + strategic LLM insights")
    print("‚úÖ Provided comprehensive understanding of foundational XML-MCP architecture")
    print("‚úÖ Identified improvement opportunities and architectural evolution paths")
    
    if DETERMINISTIC_AGENTS_AVAILABLE and STRATEGIC_AGENTS_AVAILABLE:
        print(f"‚úÖ Achieved {(deterministic_time/total_time_ms)*100:.0f}% deterministic processing with strategic AI enhancement")
    
    print(f"\nüß† This analysis demonstrates the power of cognitive triangulation:")
    print("   ‚Ä¢ Multiple analysis perspectives (structural, semantic, architectural)")
    print("   ‚Ä¢ Evidence-based confidence scoring")
    print("   ‚Ä¢ Cost-effective hybrid intelligence")
    print("   ‚Ä¢ Comprehensive understanding of complex systems")

if __name__ == "__main__":
    asyncio.run(analyze_original_x_agent_concepts())
